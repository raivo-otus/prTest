---
title: "Probabilistic workflow for univariate group comparison"
author: "Rasmus Hindstr√∂m"
date: last-modified
format:
    gfm:
        toc: true
---

# 0. Introduction 

Having established that probabilisic methods can be used as alternatives to 
classical methods in univariate group comparison, we now prepare a recommended
workflow to follow. 

# 1. Install and load packages

```{r}
#| label: package-installation
#| eval: false
#| echo: true
#| output: false

packages <- c(
    "bayesplot",
    "bayestestR",
    "brms",
    "dplyr",
    "ggplot2",
    "ggsci",
    "tidybayes"
)

to_install <- packages[!packages %in% installed.packages()[, "Package"]]
if (length(to_install) > 0) {
  install.packages(to_install)
}

bioc_pkg <- "mia"

if (!requireNamespace(bioc_pkg, quietly = TRUE)) {
  BiocManager::install(bioc_pkg)
}
```

```{r}
#| label: load-libraries
#| echo: true
#| output: false

library(bayesplot)
library(brms)
library(dplyr)
library(ggplot2)
library(mia)
library(tidybayes)
library(ggsci)
library(bayestestR)

# options
options(mc.cores = 4)
```

# 2. Prepare data

We work under the assumption that data is in a TSE -object. For more information on 
microbiome data and use of TSE -objects refer to
(Orchestrating Microbiome Analysis)[https://microbiome.github.io/OMA/docs/devel/index.html]

For demonstration purposes we show the workflow with an example dataset contained
in the `mia` -package.

```{r}
#| label: data-wrangling

data("peerj13075", package = "mia")  
tse <- peerj13075 

# You may need to agglomerate your data refer to OMA
#tse <- agglomerateByRank(tse, rank = "genus")

tse <- addAlpha(
    tse,
    assay.type = "counts",
    index = "shannon"
)

# Extracting the data into a tibble for easier modeling
df <- as_tibble(colData(tse))

# Renaming and setting levels 
lvl <- c("Adult", "Middle_age", "Elderly")
df <- df %>%
  dplyr::rename(
    group = Age,
    response = shannon
  ) %>%
  mutate(group = factor(group, levels = lvl))

str(df)
```

# 3. Fitting a probabilistic model

## 3.1. No pooling model

Without partial pooling we still get regularization from priors. The model is 
parametrized to estimate the group means directly for straight forward comparison.

```{r}
#| label: no-pool-fit
#| output: false 

fit1 <- brm(
    formula = bf(
        response ~ 0 + group,
        sigma ~ 0 + group
    ),
    data = df,
    family = student(),
)
```

```{r}
#| label: no-pool-summary
#| code-fold: true

summary(fit1)  
```

## 3.2. Partial pooling model

Fitting a hierachical model with partial pooling, provides shrinkage to correct
for multiple comparisons. Shrinkage is stronger for groups with less samples.
This type of model is typically harder to sample, and requires some tuning
to get the sampler to behave well.

```{r}
#| label: pool-fit
#| output: false 

fit2 <- brm(
    formula = bf(
        response ~ (1 | group),
        sigma ~ (1 | group)
    ),
    data = df,
    family = student(),
)

fit2 <- update(
    fit2,
    algorithm = "sampling", # "meanfield" for VI 
    control = list(adapt_delta = 0.98),
    iter = 2e4 # If using VI up iter to >2e5
)
```

```{r}
#| label: partial-pooling-summary
#| code-fold: true 
 
summary(fit2)

# Random effects
ranef(fit2)
```

Notice that compiling the model takes some time, but refitting the model with 
`update()` is considerably faster. Switching to variational inference can bring
even larger speed benefits over MCMC, but you sacrifice accuracy of the posterior.

## 3.3. Model comparison

We can quickly compare model performance by aproximating out-of-sample preformance,
using PSIS-LOO. This is the equivalent to LOO-CV in the classical paradigm. 

```{r}
#| label: model-comparison

loo(fit1, fit2) 
```

Model performance is equivalent. `se_diff` values are larger then the `elpd_diff`, there is no indication of either model being better then the other on out-of-sample prediction. 

I would argue that for our purpose, the no-pooling model is approriate when
there are so few groups. The regularisation from the priors is enough, but when 
there are more groups compared the partial pooling model would be favored.

# 4. Plotting and inference

The partial-pooling model provides correction for multiple comparisons.
Using the `tidybyes` package provides useful functions to work with and plot
the results of brms models.

## 4.1. Posterior plotting

```{r}
#| label: plotting
#| warning: false 
#| code-fold: true
#| code-summary: Plot code 
#| fig-height: 6
#| fig-width: 12
 
# Get the draws
raw_mean <- df %>%
    group_by(group) %>%
    summarise(raw_mean = mean(response))
grid <- df %>% modelr::data_grid(group)
means <- grid %>% add_epred_draws(fit2)
pred <- grid %>% add_predicted_draws(fit2)

theme_set(theme_minimal(base_size = 14))
# Density plot
p1 <- means %>%
  ggplot(aes(x = .epred, fill = group)) +
  geom_density(alpha = 0.7) +
  scale_fill_npg() +
  coord_cartesian(xlim = c(0, 2.5))
p1

# Box plot
p2 <- means %>%
  ggplot(aes(x = .epred, fill = group)) +
  geom_boxplot() +
  geom_vline(xintercept = mean(df$response), linetype = "dashed", color = "black") +
  scale_fill_npg()

p2

cap <- stringr::str_wrap(
  paste(
    "Fig.1: Mean Shannon index estimates for groups. Dashed vertical line is",
    "total population mean. Point interval bars show model estimates, thicker",
    "line represents 66% Credible Interval (CI), the thinner line represents ",
    "95% CI. Original datapoints are displayed as dots, with model predictive",
    "intervals. Vertical ticks are the raw means from data."
  )
)

p3 <- df %>%
  ggplot(aes(y = group, x = response)) +
  stat_interval(aes(x = .prediction), data = pred) +
  stat_pointinterval(
    aes(x = .epred),
    data = means,
    .width = c(0.66, 0.95),
    position = position_nudge(y = -0.1)
  ) +
  geom_point() +
  geom_point(
    aes(x = raw_mean, y = group),
    data = raw_mean,
    shape = 3,
    size = 4,
    stroke = 1.5,
    position = position_nudge(y = -0.1)
  ) +
  scale_color_brewer() +
  geom_vline(xintercept = mean(df$response), linetype = "dashed") +
  labs(
    title = "Mean Shannon index estimates",
    subtitle = "Partial pooling model",
    x = "Shannon Index",
    y = "Group",
    caption = cap
  ) +
  theme(plot.caption = element_text(hjust = 0))
p3 
```

## 4.2. Probabilistic inference

```{r}
#| label: table
#| code-fold: true
#| code-summary: Pairwise table code


# Get random intercepts
re <- ranef(fit2, summary = FALSE)$group[,,"Intercept"]
# Pairwise differences
diff_ma <- re[, "Middle_age"] - re[, "Adult"]
diff_ea <- re[, "Elderly"] - re[, "Adult"]
diff_em <- re[, "Elderly"] - re[, "Middle_age"]
# Probability of direction
pd_ma <- p_direction(diff_ma)
pd_ea <- p_direction(diff_ea)
pd_em <- p_direction(diff_em)
# Log2fc 
post <- as_draws_df(fit2)
post_a <- post$b_Intercept + post$"r_group[Adult,Intercept]"
post_m <- post$b_Intercept + post$"r_group[Middle_age,Intercept]"
post_e <- post$b_Intercept + post$"r_group[Elderly,Intercept]"
fc_ma <- log2(post_m / post_a)
fc_ea <- log2(post_e / post_a)
fc_em <- log2(post_e / post_m)
ci_ma <- quantile(fc_ma, probs = c(0.05, 0.95))
ci_ea <- quantile(fc_ea, probs = c(0.05, 0.95))
ci_em <- quantile(fc_em, probs = c(0.05, 0.95))
# Collect into a dataframe
tbl <- tibble(
  comp = c("Middle_age-Adult", "Elderly-Adult", "Elderly-Middle_age"),
  pd = c(pd_ma$pd, pd_ea$pd, pd_em$pd),
  p_like = c(pd_to_p(pd_ma$pd), pd_to_p(pd_ea$pd), pd_to_p(pd_em$pd)),
  log2fc = c(mean(fc_ma), mean(fc_ea), mean(fc_em)),
  ci_low = c(ci_ma[1], ci_ea[1], ci_em[1]),
  ci_upper = c(ci_ma[2], ci_ea[2], ci_em[2])
)

table2 <- tbl %>%
  mutate(ci = sprintf("[%.2f, %.2f]", ci_low, ci_upper)) %>%
  select(comp, log2fc, ci, pd) %>%
  gt() %>%
  tab_header(
    title = "**Probabilistic Comparisons of Groups**",
  ) %>%
  fmt_number(
    columns = c(log2fc, pd),
    decimals = 2
  ) %>%
  cols_label(
    comp = "Comparison",
    log2fc = "Mean Log2FC",
    ci = "95% CI",
    pd = "p_direction"
  )
```


